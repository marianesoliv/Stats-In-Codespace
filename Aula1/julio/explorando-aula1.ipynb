{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a5a926",
   "metadata": {},
   "source": [
    "O Polars é uma biblioteca moderna para análise de dados que surgiu em 2020, criada por Ritchie Vink como resposta às limitações de desempenho do Pandas, especialmente em grandes volumes de dados. O conceito central do Polars é oferecer uma engine de consulta analítica extremamente rápida, escrita em Rust e baseada no formato de memória columnar Apache Arrow, permitindo processamento paralelo e otimizações de memória.[1][2][3]\n",
    "\n",
    "### Surgimento e Conceito\n",
    "\n",
    "O Polars nasceu como um projeto pessoal para resolver gargalos de desempenho e uso de memória em bibliotecas tradicionais como o Pandas. Ele foi projetado para ser rápido, eficiente e escalável, especialmente para datasets grandes, utilizando técnicas de processamento paralelo e uma arquitetura close-to-the-metal, ou seja, próxima ao hardware. O Polars pode ser usado tanto de forma “eager” (execução imediata) quanto “lazy” (execução otimizada e diferida), permitindo que o usuário defina pipelines de transformação de dados que são otimizados antes da execução.[2][3][4][1]\n",
    "\n",
    "### Vantagens do Polars\n",
    "\n",
    "- **Desempenho**: O Polars é frequentemente 5 a 10 vezes mais rápido que o Pandas em operações comuns, podendo chegar a 30x em benchmarks específicos.[5][3][6]\n",
    "- **Eficiência de memória**: Utiliza o formato columnar Apache Arrow, reduzindo o uso de memória e permitindo processar datasets maiores do que a RAM disponível, graças ao streaming e ao suporte a dados fora da memória.[3][2]\n",
    "- **Paralelismo**: O Polars aproveita todos os núcleos do processador automaticamente, sem necessidade de configuração adicional.[2][3]\n",
    "- **Sintaxe expressiva**: Oferece uma API intuitiva e encadeável, facilitando a leitura e manutenção do código.[7][4]\n",
    "- **Integração com o ecossistema Python**: Permite fácil integração com outras bibliotecas populares, como Scikit-learn, Matplotlib e frameworks de machine learning.[7][3]\n",
    "- **Open source e ativo**: O Polars é open source, possui uma comunidade crescente e está em constante evolução.[1][2]\n",
    "\n",
    "### Exemplo concreto\n",
    "\n",
    "Imagine que você está analisando dados de tráfego de uma cidade, com milhões de registros de veículos. Com o Pandas, operações como agrupamento, filtragem e agregação podem ser lentas e exigir muita memória. Já com o Polars, essas mesmas operações são executadas rapidamente, permitindo que você explore diferentes cenários e faça ajustes em tempo real, sem precisar esperar minutos ou horas para ver o resultado.[3][2]\n",
    "\n",
    "### Conexão com o que já foi aprendido\n",
    "\n",
    "Se você já usou o Pandas, perceberá que o Polars segue uma lógica semelhante, mas com ganhos de desempenho e eficiência que fazem toda a diferença em projetos reais de engenharia de transporte, onde dados são grandes e decisões precisam ser rápidas.[7][3]\n",
    "\n",
    "### Estimulando a curiosidade\n",
    "\n",
    "E se você pudesse processar um dataset de 10 GB em segundos, sem precisar de um cluster de computadores? O Polars está tornando isso possível. Que outros desafios de análise de dados poderiam ser resolvidos com uma ferramenta tão eficiente?\n",
    "\n",
    "***\n",
    "\n",
    "O Polars é uma excelente opção para quem busca desempenho, eficiência e escalabilidade em análise de dados, especialmente em projetos de engenharia e ciência de dados aplicada.[2][3][7]\n",
    "\n",
    "[1](https://en.wikipedia.org/wiki/Polars_(software))\n",
    "[2](https://pola.rs)\n",
    "[3](https://deepnote.com/blog/ultimate-guide-to-the-polars-library-in-python)\n",
    "[4](https://www.datacamp.com/blog/an-introduction-to-polars-python-s-tool-for-large-scale-data-analysis)\n",
    "[5](https://www.stratascratch.com/blog/polars-vs-pandas/)\n",
    "[6](https://blog.jetbrains.com/pycharm/2024/07/polars-vs-pandas/)\n",
    "[7](https://www.geeksforgeeks.org/data-analysis/mastering-polars-high-efficiency-data-analysis-and-manipulation/)\n",
    "[8](https://dl.acm.org/doi/10.1145/3661167.3661203)\n",
    "[9](https://www.mdpi.com/2073-431X/14/8/319)\n",
    "[10](https://www.sciendo.com/article/10.2478/amns.2023.2.01212)\n",
    "[11](https://proceedings.gpntbsib.ru/jour/article/view/942)\n",
    "[12](https://joss.theoj.org/papers/10.21105/joss.06943)\n",
    "[13](https://www.tandfonline.com/doi/full/10.1080/01616846.2023.2296179)\n",
    "[14](http://dspace.ada.edu.az/xmlui/handle/20.500.12181/1180)\n",
    "[15](http://librinfosciences.knukim.edu.ua/article/view/318289)\n",
    "[16](https://onlinelibrary.wiley.com/doi/10.1111/1750-0206.12725)\n",
    "[17](https://alhayat.or.id/index.php/alhayat/article/view/440)\n",
    "[18](https://arxiv.org/pdf/0805.1165.pdf)\n",
    "[19](https://www.atmos-chem-phys.net/18/13547/2018/acp-18-13547-2018.pdf)\n",
    "[20](http://arxiv.org/pdf/2409.01363.pdf)\n",
    "[21](https://acp.copernicus.org/articles/15/3873/2015/acp-15-3873-2015.pdf)\n",
    "[22](https://arxiv.org/pdf/0805.4389.pdf)\n",
    "[23](https://arxiv.org/abs/0804.3593)\n",
    "[24](https://arxiv.org/pdf/1003.4682.pdf)\n",
    "[25](https://arxiv.org/pdf/1205.6276.pdf)\n",
    "[26](https://data-ai.theodo.com/en/technical-blog/polars-vs-pandas)\n",
    "[27](https://github.com/pola-rs/polars)\n",
    "[28](https://towardsdatascience.com/rust-polars-unlocking-high-performance-data-analysis-part-1-ce42af370ece/)\n",
    "[29](https://www.reddit.com/r/Python/comments/1jg402b/polars_vs_pandas/)\n",
    "[30](https://dskrzypiec.dev/polars/)\n",
    "[31](https://towardsdatascience.com/polars-vs-pandas-an-independent-speed-comparison/)\n",
    "[32](https://pola.rs/about-us/)\n",
    "[33](https://realpython.com/polars-vs-pandas/)\n",
    "[34](https://docs.pola.rs/user-guide/migration/pandas/)\n",
    "[35](https://pypi.org/project/polars/)\n",
    "[36](https://www.factspan.com/blogs/choosing-polars-over-pandas-for-high-performance-data-analysis/)\n",
    "[37](https://labs.quansight.org/blog/dataframe-group-by)\n",
    "[38](https://coditation.com/blog/high-performance-data-analysis-with-polars-a-comprehensive-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96299b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo de Tamanhos em Disco:\n",
      "- .tab:      40.26 MB\n",
      "- .parquet:  4.22 MB\n",
      "- Fator de redução: 9.53x (tab/parquet)\n",
      "\n",
      "Tempos (segundos):\n",
      "- Leitura .tab:          0.2584s\n",
      "- Escrita .parquet:      0.1240s\n",
      "- Leitura .parquet:      0.0352s\n",
      "- Describe .tab:         0.1097s\n",
      "- Describe .parquet:     0.0694s\n",
      "\n",
      "Memória estimada dos DataFrames:\n",
      "- DF (.tab):      43.73 MB\n",
      "- DF (.parquet):  43.73 MB\n",
      "\n",
      "Esquema (dtypes) detectado:\n",
      "Schema({'day': String, 'origin': String, 'destination': String, 'travel_count_no_factor': Int64, 'travel_count_fix_factor': Int64, 'travell_count_adap_factor': Int64})\n"
     ]
    }
   ],
   "source": [
    "# Conversão de .tab para Polars (.parquet) e comparação de tempo e espaço com análise descritiva\n",
    "\n",
    "# Instala Polars caso não esteja disponível\n",
    "try:\n",
    "    import polars as pl\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"polars>=1.0.0\"])\n",
    "    import polars as pl\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Caminhos de arquivo - tem que descomprimir o arquivo antes - gunzip \"nome-arq\"\n",
    "tab_path = \"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.tab\"\n",
    "parquet_path = os.path.splitext(tab_path)[0] + \".parquet\"\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.2f} {unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.2f} PB\"\n",
    "\n",
    "# 1) Ler .tab com Polars e análise descritiva (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_tab = pl.read_csv(\n",
    "    tab_path,\n",
    "    separator=\"\\t\",\n",
    "    infer_schema_length=10000,\n",
    "    low_memory=True,\n",
    "    null_values=[\"\", \"NA\", \"NaN\", \"null\", \"NULL\"]\n",
    ")\n",
    "t_read_tab = time.perf_counter() - t0\n",
    "\n",
    "mem_tab = df_tab.estimated_size()  # bytes\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_tab = df_tab.describe()\n",
    "t_desc_tab = time.perf_counter() - t0\n",
    "\n",
    "# 2) Converter para Parquet (formato coluna eficiente) e medir espaço/tempo\n",
    "t0 = time.perf_counter()\n",
    "df_tab.write_parquet(parquet_path, compression=\"zstd\", statistics=True)\n",
    "t_write_parquet = time.perf_counter() - t0\n",
    "\n",
    "size_tab = os.path.getsize(tab_path)\n",
    "size_parquet = os.path.getsize(parquet_path)\n",
    "\n",
    "# 3) Ler Parquet e fazer a mesma análise (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_parquet = pl.read_parquet(parquet_path)\n",
    "t_read_parquet = time.perf_counter() - t0\n",
    "\n",
    "mem_parquet = df_parquet.estimated_size()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_parquet = df_parquet.describe()\n",
    "t_desc_parquet = time.perf_counter() - t0\n",
    "\n",
    "# 4) Resultados\n",
    "print(\"Resumo de Tamanhos em Disco:\")\n",
    "print(f\"- .tab:      {human_bytes(size_tab)}\")\n",
    "print(f\"- .parquet:  {human_bytes(size_parquet)}\")\n",
    "if size_tab > 0:\n",
    "    print(f\"- Fator de redução: {size_tab/size_parquet:.2f}x (tab/parquet)\")\n",
    "\n",
    "print(\"\\nTempos (segundos):\")\n",
    "print(f\"- Leitura .tab:          {t_read_tab:.4f}s\")\n",
    "print(f\"- Escrita .parquet:      {t_write_parquet:.4f}s\")\n",
    "print(f\"- Leitura .parquet:      {t_read_parquet:.4f}s\")\n",
    "print(f\"- Describe .tab:         {t_desc_tab:.4f}s\")\n",
    "print(f\"- Describe .parquet:     {t_desc_parquet:.4f}s\")\n",
    "\n",
    "print(\"\\nMemória estimada dos DataFrames:\")\n",
    "print(f\"- DF (.tab):      {human_bytes(mem_tab)}\")\n",
    "print(f\"- DF (.parquet):  {human_bytes(mem_parquet)}\")\n",
    "\n",
    "print(\"\\nEsquema (dtypes) detectado:\")\n",
    "print(df_tab.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4b5362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>day</th><th>origin</th><th>destination</th><th>travel_count_no_factor</th><th>travel_count_fix_factor</th><th>travell_count_adap_factor</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;ANCHIETA&quot;</td><td>173</td><td>901</td><td>16497</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;BANGU&quot;</td><td>50</td><td>245</td><td>4332</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;BARRA DA TIJUCA&quot;</td><td>16</td><td>77</td><td>1341</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;BELFORD ROXO&quot;</td><td>14</td><td>97</td><td>1542</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;BOTAFOGO&quot;</td><td>11</td><td>52</td><td>903</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;ITABORAI&quot;</td><td>1</td><td>5</td><td>68</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;ITAGUAI&quot;</td><td>14</td><td>85</td><td>1557</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;JACAREPAGUA&quot;</td><td>34</td><td>188</td><td>3039</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;JACAREZINHO&quot;</td><td>3</td><td>15</td><td>311</td></tr><tr><td>&quot;01/01/2014&quot;</td><td>&quot;ANCHIETA&quot;</td><td>&quot;JAPERI&quot;</td><td>2</td><td>16</td><td>414</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 6)\n",
       "┌────────────┬──────────┬─────────────────┬──────────────────┬──────────────────┬──────────────────┐\n",
       "│ day        ┆ origin   ┆ destination     ┆ travel_count_no_ ┆ travel_count_fix ┆ travell_count_ad │\n",
       "│ ---        ┆ ---      ┆ ---             ┆ factor           ┆ _factor          ┆ ap_factor        │\n",
       "│ str        ┆ str      ┆ str             ┆ ---              ┆ ---              ┆ ---              │\n",
       "│            ┆          ┆                 ┆ i64              ┆ i64              ┆ i64              │\n",
       "╞════════════╪══════════╪═════════════════╪══════════════════╪══════════════════╪══════════════════╡\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ ANCHIETA        ┆ 173              ┆ 901              ┆ 16497            │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ BANGU           ┆ 50               ┆ 245              ┆ 4332             │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ BARRA DA TIJUCA ┆ 16               ┆ 77               ┆ 1341             │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ BELFORD ROXO    ┆ 14               ┆ 97               ┆ 1542             │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ BOTAFOGO        ┆ 11               ┆ 52               ┆ 903              │\n",
       "│ …          ┆ …        ┆ …               ┆ …                ┆ …                ┆ …                │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ ITABORAI        ┆ 1                ┆ 5                ┆ 68               │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ ITAGUAI         ┆ 14               ┆ 85               ┆ 1557             │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ JACAREPAGUA     ┆ 34               ┆ 188              ┆ 3039             │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ JACAREZINHO     ┆ 3                ┆ 15               ┆ 311              │\n",
       "│ 01/01/2014 ┆ ANCHIETA ┆ JAPERI          ┆ 2                ┆ 16               ┆ 414              │\n",
       "└────────────┴──────────┴─────────────────┴──────────────────┴──────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando Polars SQL para ler as primeiras 20 linhas\n",
    "import polars as pl\n",
    "\n",
    "parquet_path = \"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.parquet\"\n",
    "df_parquet = pl.read_parquet(parquet_path)\n",
    "\n",
    "\n",
    "# Use pl.SQLContext para registrar o dataframe corretamente\n",
    "ctx = pl.SQLContext()\n",
    "ctx.register(\"df_parquet\", df_parquet)  # Registra o DataFrame para uso no SQL\n",
    "\n",
    "# Realiza a consulta SQL (resultado normalmente é LazyFrame ou DataFrame)\n",
    "result = ctx.execute(\"SELECT * FROM df_parquet LIMIT 20\")\n",
    "\n",
    "# Para notebooks Jupyter, retorne o DataFrame como último objeto da célula:\n",
    "result.collect() # Exibe as linhas como tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b716c7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>len</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>867975</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌────────┐\n",
       "│ len    │\n",
       "│ ---    │\n",
       "│ u32    │\n",
       "╞════════╡\n",
       "│ 867975 │\n",
       "└────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contagem da quantidade de registros total, que nesse caso significa o total de combinações únicas de (day, origin, destination)\n",
    "\n",
    "# Use pl.SQLContext para registrar o dataframe corretamente\n",
    "ctx = pl.SQLContext()\n",
    "ctx.register(\"df_parquet\", df_parquet)  # Registra o DataFrame para uso no SQL\n",
    "\n",
    "# Realiza a consulta SQL (resultado normalmente é LazyFrame ou DataFrame)\n",
    "result = ctx.execute(\"SELECT count(*) FROM df_parquet\")\n",
    "\n",
    "# Para notebooks Jupyter, retorne o DataFrame como último objeto da célula:\n",
    "result.collect() # Exibe as linhas como tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00c3406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>day</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>363</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────┐\n",
       "│ day │\n",
       "│ --- │\n",
       "│ u32 │\n",
       "╞═════╡\n",
       "│ 363 │\n",
       "└─────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contagem de valores distintos em (day, origin, destination)\n",
    "\n",
    "# Use pl.SQLContext para registrar o dataframe corretamente\n",
    "ctx = pl.SQLContext()\n",
    "ctx.register(\"df_parquet\", df_parquet)  # Registra o DataFrame para uso no SQL\n",
    "\n",
    "# Realiza a consulta SQL (resultado normalmente é LazyFrame ou DataFrame)\n",
    "result = ctx.execute(\"SELECT count(DISTINCT day) FROM df_parquet\")\n",
    "\n",
    "# Para notebooks Jupyter, retorne o DataFrame como último objeto da célula:\n",
    "result.collect() # Exibe as linhas como tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553907ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10,)\n",
      "Series: 'day' [date]\n",
      "[\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "]\n",
      "Schema({'day': Date, 'origin': String, 'destination': String, 'travel_count_no_factor': Int64, 'travel_count_fix_factor': Int64, 'travell_count_adap_factor': Int64})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Converter a coluna 'day' de string para date, usando o formato dd/mm/yyyy\n",
    "df_parquet = df_parquet.with_columns(\n",
    "    pl.col('day').str.strptime(pl.Date, format='%d/%m/%Y').alias('day')\n",
    ")\n",
    "\n",
    "# Opcional: Se quiser manter o nome original e sobrescrever\n",
    "# df_parquet = df_parquet.with_columns(\n",
    "#     pl.col('day').str.strptime(pl.Date, format='%d/%m/%Y')\n",
    "# )\n",
    "\n",
    "# Verificar o resultado\n",
    "print(df_parquet['day'].head())\n",
    "print(df_parquet.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d371d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'day': Date, 'origin': String, 'destination': String, 'travel_count_no_factor': Int64, 'travel_count_fix_factor': Int64, 'travell_count_adap_factor': Int64})\n",
      "shape: (10,)\n",
      "Series: 'day' [date]\n",
      "[\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "\t2014-01-01\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gravar o DataFrame modificado de volta no arquivo Parquet original\n",
    "df_parquet.write_parquet(\"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.parquet\")\n",
    "\n",
    "# Opcional: Verificar se foi salvo corretamente lendo de volta\n",
    "df_check = pl.read_parquet(\"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.parquet\")\n",
    "print(df_check.schema)\n",
    "print(df_check['day'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebc5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 7)\n",
      "┌────────────┬──────────────┬─────────────┬─────────────┬──────────────┬─────────────┬─────────────┐\n",
      "│ statistic  ┆ day          ┆ origin      ┆ destination ┆ travel_count ┆ travel_coun ┆ travell_cou │\n",
      "│ ---        ┆ ---          ┆ ---         ┆ ---         ┆ _no_factor   ┆ t_fix_facto ┆ nt_adap_fac │\n",
      "│ str        ┆ str          ┆ str         ┆ str         ┆ ---          ┆ r           ┆ tor         │\n",
      "│            ┆              ┆             ┆             ┆ f64          ┆ ---         ┆ ---         │\n",
      "│            ┆              ┆             ┆             ┆              ┆ f64         ┆ f64         │\n",
      "╞════════════╪══════════════╪═════════════╪═════════════╪══════════════╪═════════════╪═════════════╡\n",
      "│ count      ┆ 867975       ┆ 867975      ┆ 867975      ┆ 867975.0     ┆ 867975.0    ┆ 867975.0    │\n",
      "│ null_count ┆ 0            ┆ 0           ┆ 0           ┆ 0.0          ┆ 0.0         ┆ 0.0         │\n",
      "│ mean       ┆ 2014-07-01   ┆ null        ┆ null        ┆ 167.592712   ┆ 771.88021   ┆ 5064.732094 │\n",
      "│            ┆ 18:08:31.720 ┆             ┆             ┆              ┆             ┆             │\n",
      "│            ┆ 729          ┆             ┆             ┆              ┆             ┆             │\n",
      "│ std        ┆ null         ┆ null        ┆ null        ┆ 1063.177787  ┆ 4184.228925 ┆ 24025.06017 │\n",
      "│            ┆              ┆             ┆             ┆              ┆             ┆ 3           │\n",
      "│ min        ┆ 2013-12-31   ┆ ANCHIETA    ┆ ANCHIETA    ┆ 1.0          ┆ 1.0         ┆ 10.0        │\n",
      "│ 25%        ┆ 2014-04-01   ┆ null        ┆ null        ┆ 4.0          ┆ 23.0        ┆ 193.0       │\n",
      "│ 50%        ┆ 2014-07-02   ┆ null        ┆ null        ┆ 22.0         ┆ 106.0       ┆ 858.0       │\n",
      "│ 75%        ┆ 2014-09-30   ┆ null        ┆ null        ┆ 81.0         ┆ 411.0       ┆ 3029.0      │\n",
      "│ max        ┆ 2015-01-01   ┆ VILA ISABEL ┆ VILA ISABEL ┆ 44612.0      ┆ 150287.0    ┆ 774785.0    │\n",
      "└────────────┴──────────────┴─────────────┴─────────────┴──────────────┴─────────────┴─────────────┘\n",
      "\n",
      "Esquema (dtypes):\n",
      "Schema({'day': Date, 'origin': String, 'destination': String, 'travel_count_no_factor': Int64, 'travel_count_fix_factor': Int64, 'travell_count_adap_factor': Int64})\n",
      "\n",
      "Shape: (867975, 6)\n"
     ]
    }
   ],
   "source": [
    "# Exibe informações do DataFrame Polars (similar ao df.info() do pandas)\n",
    "print(df_parquet.describe())\n",
    "print(\"\\nEsquema (dtypes):\")\n",
    "print(df_parquet.schema)\n",
    "print(f\"\\nShape: {df_parquet.shape}\")\n",
    "\n",
    "# Escala de mensuração das variáveis:\n",
    "# - day: categórica ordinal (datas ordenáveis)\n",
    "# - origin: categórica nominal\n",
    "# - destination: categórica nominal\n",
    "# - travel_count_no_factor: quantitativa discreta\n",
    "# - travel_count_fix_factor: quantitativa discreta\n",
    "# - travel_count_adap_factor: quantitativa discreta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4388a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (16_772, 3)\n",
      "┌─────────────────────────┬───────┬──────────┐\n",
      "│ travel_count_fix_factor ┆ count ┆ %        │\n",
      "│ ---                     ┆ ---   ┆ ---      │\n",
      "│ i64                     ┆ u32   ┆ f64      │\n",
      "╞═════════════════════════╪═══════╪══════════╡\n",
      "│ 1                       ┆ 2755  ┆ 0.317405 │\n",
      "│ 2                       ┆ 4847  ┆ 0.558426 │\n",
      "│ 3                       ┆ 14444 ┆ 1.664103 │\n",
      "│ 4                       ┆ 19660 ┆ 2.265042 │\n",
      "│ 5                       ┆ 20156 ┆ 2.322187 │\n",
      "│ …                       ┆ …     ┆ …        │\n",
      "│ 141153                  ┆ 1     ┆ 0.000115 │\n",
      "│ 142956                  ┆ 1     ┆ 0.000115 │\n",
      "│ 143139                  ┆ 1     ┆ 0.000115 │\n",
      "│ 144616                  ┆ 1     ┆ 0.000115 │\n",
      "│ 150287                  ┆ 1     ┆ 0.000115 │\n",
      "└─────────────────────────┴───────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Tabela de frequências absolutas (contagem) e relativas (%) da variável 'travel_count_fix_factor'\n",
    "\n",
    "contagem = df_parquet['travel_count_fix_factor'].value_counts().sort('travel_count_fix_factor')\n",
    "percent = (contagem['count'] / contagem['count'].sum() * 100).alias('%')\n",
    "\n",
    "tabela_freq = contagem.with_columns(percent)\n",
    "print(tabela_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c3bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (54, 3)\n",
      "┌─────────────────┬───────┬──────────┐\n",
      "│ origin          ┆ count ┆ %        │\n",
      "│ ---             ┆ ---   ┆ ---      │\n",
      "│ str             ┆ u32   ┆ f64      │\n",
      "╞═════════════════╪═══════╪══════════╡\n",
      "│ ANCHIETA        ┆ 17096 ┆ 1.969642 │\n",
      "│ BANGU           ┆ 17339 ┆ 1.997638 │\n",
      "│ BARRA DA TIJUCA ┆ 18363 ┆ 2.115614 │\n",
      "│ BELFORD ROXO    ┆ 16997 ┆ 1.958236 │\n",
      "│ BOTAFOGO        ┆ 18733 ┆ 2.158242 │\n",
      "│ …               ┆ …     ┆ …        │\n",
      "│ TANGUA          ┆ 8501  ┆ 0.979406 │\n",
      "│ TERESOPOLIS     ┆ 11954 ┆ 1.377229 │\n",
      "│ TIJUCA          ┆ 18550 ┆ 2.137158 │\n",
      "│ VIGARIO GERAL   ┆ 18033 ┆ 2.077594 │\n",
      "│ VILA ISABEL     ┆ 18137 ┆ 2.089576 │\n",
      "└─────────────────┴───────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Tabela de frequências absolutas (contagem) e relativas (%) da variável 'origin'\n",
    "\n",
    "contagem_origin = df_parquet['origin'].value_counts().sort('origin')\n",
    "percent_origin = (contagem_origin['count'] / contagem_origin['count'].sum() * 100).alias('%')\n",
    "\n",
    "tabela_freq_origin = contagem_origin.with_columns(percent_origin)\n",
    "print(tabela_freq_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a15755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stemgraphic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m \u001b[38;5;66;03m#biblioteca de visualização de dados\u001b[39;00m\n\u001b[32m     17\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install stemgraphic\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstemgraphic\u001b[39;00m \u001b[38;5;66;03m#biblioteca para elaboração do gráfico de ramo-e-folhas\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m norm \u001b[38;5;66;03m#para plotagem da distribuição normal no histograma\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'stemgraphic'"
     ]
    }
   ],
   "source": [
    "# adaptar para a base de mobilidade do RJ\n",
    "\n",
    "##############################################################################\n",
    "#                     MANUAL DE ANÁLISE DE DADOS                             #\n",
    "#                Luiz Paulo Fávero e Patrícia Belfiore                       #\n",
    "#                            Capítulo 02                                     #\n",
    "##############################################################################\n",
    "\n",
    "##############################################################################\n",
    "#                     IMPORTAÇÃO DOS PACOTES NECESSÁRIOS                     #\n",
    "##############################################################################\n",
    "\n",
    "import pandas as pd #manipulação de dados em formato de dataframe\n",
    "import numpy as np #biblioteca para operações matemáticas multidimensionais\n",
    "from scipy.stats import skew #cálculo da assimetria\n",
    "from scipy.stats import kurtosis #cálculo da curtose\n",
    "import seaborn as sns #biblioteca de visualização de informações estatísticas\n",
    "import matplotlib.pyplot as plt #biblioteca de visualização de dados\n",
    "import stemgraphic #biblioteca para elaboração do gráfico de ramo-e-folhas\n",
    "from scipy.stats import norm #para plotagem da distribuição normal no histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ab1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela de frequências absolutas (contagem) e relativas (%) da variável 'preco'\n",
    "\n",
    "contagem = df_cotacoes['preco'].value_counts()\n",
    "percent = df_cotacoes['preco'].value_counts(normalize=True)\n",
    "pd.concat([contagem, percent], axis=1, keys=['contagem', '%'], sort=True)\n",
    "\n",
    "# Estatísticas descritivas univariadas da variável 'preco'\n",
    "df_cotacoes['preco'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas de assimetria e curtose para a variável 'preco'\n",
    "skew(df_cotacoes, axis=0, bias=True) # igual ao Stata\n",
    "skew(df_cotacoes, axis=0, bias=False) # igual ao SPSS\n",
    "kurtosis(df_cotacoes, axis=0, bias=False) # igual ao SPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#   GRÁFICOS: HISTOGRAMA, RAMO-E-FOLHAS E BOXPLOT PARA A VARIÁVEL 'preco'    #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ca6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(data=df_cotacoes, x='preco', bins=7, color='darkorchid')\n",
    "plt.xlabel('Preço', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma com Kernel density estimation (KDE)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(data=df_cotacoes, x='preco', kde=True, bins=7, color='darkorchid')\n",
    "plt.xlabel('Preço', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.legend(['Kernel density estimation (KDE)'], fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma com curva normal\n",
    "plt.figure(figsize=(15,10))\n",
    "mu, std = norm.fit(df_cotacoes['preco'])\n",
    "plt.hist(df_cotacoes['preco'], bins=7, density=True, alpha=0.6, color='silver')\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2, color='darkorchid')\n",
    "plt.xlabel('Preço', fontsize=20)\n",
    "plt.ylabel('Densidade', fontsize=20)\n",
    "plt.legend(['Curva Normal'], fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de ramo-e-folhas para a variável 'preco'\n",
    "stemgraphic.stem_graphic(df_cotacoes['preco'], scale = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot da variável 'preco' - pacote 'matplotlib'\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.boxplot(df_cotacoes['preco'])\n",
    "plt.title('Preço', fontsize=17)\n",
    "plt.ylabel('Preço', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed60fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot da variável 'preco' - pacote 'seaborn'\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(df_cotacoes['preco'], linewidth=2, orient='v', color='purple')\n",
    "sns.stripplot(df_cotacoes['preco'], color=\"orange\", jitter=0.1, size=7)\n",
    "plt.title('Preço', fontsize=17)\n",
    "plt.xlabel('Preço', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
